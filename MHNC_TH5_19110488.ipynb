{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3VwuOTqmdzDyyFcITd5/X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"590b7cb4af7948c3bf83ab1d0c8b5ce5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_58e0a3a96fe64e4989574b8d4caebdb0","IPY_MODEL_6542f690b413430781b99c8904495627","IPY_MODEL_77bf77c07b604e9883d9184a74b57d7c"],"layout":"IPY_MODEL_df09e6a2f0954b5cbbaeff5bd60b9cea"}},"58e0a3a96fe64e4989574b8d4caebdb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8aa6950f822f4de2a7ff11da4c6394b3","placeholder":"​","style":"IPY_MODEL_726e80489ab24721b1d91a14d03f04d5","value":"Downloading: 100%"}},"6542f690b413430781b99c8904495627":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_808b6d5918a4402699f7bb6d42de1c68","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfa2dfb3303a45edaaf02397ab34643a","value":570}},"77bf77c07b604e9883d9184a74b57d7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0171eb5afe554e5e8d06476ea51f59d2","placeholder":"​","style":"IPY_MODEL_5cba0ae4958b446d83960eebdb05655c","value":" 570/570 [00:00&lt;00:00, 17.4kB/s]"}},"df09e6a2f0954b5cbbaeff5bd60b9cea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aa6950f822f4de2a7ff11da4c6394b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"726e80489ab24721b1d91a14d03f04d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"808b6d5918a4402699f7bb6d42de1c68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfa2dfb3303a45edaaf02397ab34643a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0171eb5afe554e5e8d06476ea51f59d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cba0ae4958b446d83960eebdb05655c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64d1caa771fa4ece9549e7caf6aef187":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e478c42263a0408983f6800f850bfd6f","IPY_MODEL_588110a441c3431d98fb6e19603eeab0","IPY_MODEL_df7b72d1dc94489ba61d3da216b6860e"],"layout":"IPY_MODEL_bf75a3fa0fc84820b8eb17ab1117585f"}},"e478c42263a0408983f6800f850bfd6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50f6a197a97c42c799aea0fc9657548d","placeholder":"​","style":"IPY_MODEL_6ebcbda7061041a58e126e16d24f9136","value":"Downloading: 100%"}},"588110a441c3431d98fb6e19603eeab0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_249580aeee4e43459479d2689fdbb1cf","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0756b7ff41f34519af74c209645f123f","value":29}},"df7b72d1dc94489ba61d3da216b6860e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_550c0389df224a4982d6e463d22f9f7c","placeholder":"​","style":"IPY_MODEL_81507a37d46445b6a681149840277d24","value":" 29.0/29.0 [00:00&lt;00:00, 999B/s]"}},"bf75a3fa0fc84820b8eb17ab1117585f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50f6a197a97c42c799aea0fc9657548d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ebcbda7061041a58e126e16d24f9136":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"249580aeee4e43459479d2689fdbb1cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0756b7ff41f34519af74c209645f123f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"550c0389df224a4982d6e463d22f9f7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81507a37d46445b6a681149840277d24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10f6f8c27f7c4d9e8491b9c1ebcf43a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0cfc0f602dd3467c81eb9b0f51c99375","IPY_MODEL_3cc555752cab4521b440b865b60f4f5b","IPY_MODEL_f6b3554691cc4e37b3e33ec3fad79f16"],"layout":"IPY_MODEL_72ead08ca2434939a055e64a3164f9e0"}},"0cfc0f602dd3467c81eb9b0f51c99375":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c11992812a564c8ca5d9bc4127ce9b01","placeholder":"​","style":"IPY_MODEL_83e1d238e31a4e89801ee3e32c4e5e6e","value":"Downloading: 100%"}},"3cc555752cab4521b440b865b60f4f5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38c2fe6a799d493297f29be3f13300fc","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_247b2ed178734636bf01e1aba2f8ea5c","value":213450}},"f6b3554691cc4e37b3e33ec3fad79f16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9327fe76247d4f35872df5464371b790","placeholder":"​","style":"IPY_MODEL_0ad9d7cf4b134310830ea36f4e17f656","value":" 213k/213k [00:00&lt;00:00, 279kB/s]"}},"72ead08ca2434939a055e64a3164f9e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c11992812a564c8ca5d9bc4127ce9b01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83e1d238e31a4e89801ee3e32c4e5e6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38c2fe6a799d493297f29be3f13300fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"247b2ed178734636bf01e1aba2f8ea5c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9327fe76247d4f35872df5464371b790":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ad9d7cf4b134310830ea36f4e17f656":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30d98744e09b4359bf768a393b3d07cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_05956bd6fada437ab6cb4fb34775e089","IPY_MODEL_b3ed5f1078874830b9c027ed71d0596b","IPY_MODEL_43d1d397539a4b22a0986541858a235c"],"layout":"IPY_MODEL_118e7e26831e4ab3bbf56304e0741cd6"}},"05956bd6fada437ab6cb4fb34775e089":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13dbe7abe6624ce2b47e5010c73c700b","placeholder":"​","style":"IPY_MODEL_6a8d8d1f279646babdba177c0fbcf753","value":"Downloading: 100%"}},"b3ed5f1078874830b9c027ed71d0596b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3d55ce66e5b465e8c2a5d434f07cd88","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d799c5aeaca6462e8c95eb68d707d417","value":435797}},"43d1d397539a4b22a0986541858a235c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e1d9e7371934ecb96a93842ccec49bd","placeholder":"​","style":"IPY_MODEL_45725aa555524a7fa185c335ad3f0c24","value":" 436k/436k [00:00&lt;00:00, 297kB/s]"}},"118e7e26831e4ab3bbf56304e0741cd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13dbe7abe6624ce2b47e5010c73c700b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a8d8d1f279646babdba177c0fbcf753":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3d55ce66e5b465e8c2a5d434f07cd88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d799c5aeaca6462e8c95eb68d707d417":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e1d9e7371934ecb96a93842ccec49bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45725aa555524a7fa185c335ad3f0c24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3df7d791e7f34e9dae933f943f32b61c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5de1b326da56446e8787dafb936497fb","IPY_MODEL_055d3495fd6440818450070b527b3737","IPY_MODEL_13c9fa899bbe4604aa242687526147c0"],"layout":"IPY_MODEL_00ef9de6759a4552888f87a25d17ac90"}},"5de1b326da56446e8787dafb936497fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_637d247cef9146c98ac697ee135485ae","placeholder":"​","style":"IPY_MODEL_b6cc55713a674a338ecd1af8cd22ae59","value":"Downloading: 100%"}},"055d3495fd6440818450070b527b3737":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11caa175a7724b6d89776e0c87f968c2","max":526681800,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30395471d98440cba38591d457976592","value":526681800}},"13c9fa899bbe4604aa242687526147c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d0d3c46847b4cf3b03de365ba03a583","placeholder":"​","style":"IPY_MODEL_77541e5cd09d4ad9935dd7b6f726ce75","value":" 527M/527M [00:08&lt;00:00, 62.0MB/s]"}},"00ef9de6759a4552888f87a25d17ac90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"637d247cef9146c98ac697ee135485ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6cc55713a674a338ecd1af8cd22ae59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11caa175a7724b6d89776e0c87f968c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30395471d98440cba38591d457976592":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d0d3c46847b4cf3b03de365ba03a583":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77541e5cd09d4ad9935dd7b6f726ce75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18c6a42936a04d6ab9576ad705087d4f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd06d76784a343f898cdf1c2ebea535f","IPY_MODEL_d6093060b7dc4a088830994d0286c56a","IPY_MODEL_096ef0abbfe44b6cb5a6c15e46c002a2"],"layout":"IPY_MODEL_6da6ee62628940c19facdb908045fbc2"}},"bd06d76784a343f898cdf1c2ebea535f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60f0242ed2ca4a308e6c888fa88364e3","placeholder":"​","style":"IPY_MODEL_29fc053994374b11a9977821b15e13d5","value":"Downloading: 100%"}},"d6093060b7dc4a088830994d0286c56a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_088ae864ae9b4a6d820c48a1ae020ac6","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f135580612f140feb1b765bafbd3916a","value":760}},"096ef0abbfe44b6cb5a6c15e46c002a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7cf75f356ca4c4daf98f5a7a9bea485","placeholder":"​","style":"IPY_MODEL_65f3910be1be49ef8f8276525dd3ed5c","value":" 760/760 [00:00&lt;00:00, 20.6kB/s]"}},"6da6ee62628940c19facdb908045fbc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f0242ed2ca4a308e6c888fa88364e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29fc053994374b11a9977821b15e13d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"088ae864ae9b4a6d820c48a1ae020ac6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f135580612f140feb1b765bafbd3916a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7cf75f356ca4c4daf98f5a7a9bea485":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65f3910be1be49ef8f8276525dd3ed5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"8Oa2rWl_2XHC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669560952694,"user_tz":-420,"elapsed":759,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"c041ac4c-9eb7-4e7f-8df6-9611d257c356"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-11-27 14:55:50--  https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 503663 (492K) [text/plain]\n","Saving to: ‘spam.csv’\n","\n","spam.csv            100%[===================>] 491.86K  --.-KB/s    in 0.005s  \n","\n","2022-11-27 14:55:51 (94.0 MB/s) - ‘spam.csv’ saved [503663/503663]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q7XkRwt-6Tch","executionInfo":{"status":"ok","timestamp":1669560966175,"user_tz":-420,"elapsed":10379,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"ccfc5046-14d8-4696-fb48-5ce236a0eac9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 37.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 58.3 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 71.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.0 tokenizers-0.13.2 transformers-4.24.0\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import regex as re\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, TFAutoModel, AutoConfig"],"metadata":{"id":"1cbssIps4ocn","executionInfo":{"status":"ok","timestamp":1669560971151,"user_tz":-420,"elapsed":3137,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv(\"/content/spam.csv\", encoding = \"ISO-8859-1\")\n","data.drop([\"Unnamed: 2\", \"Unnamed: 3\",\"Unnamed: 4\"], axis=1, inplace=True)\n","data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"gGNYguYJ4tRz","executionInfo":{"status":"ok","timestamp":1669560971156,"user_tz":-420,"elapsed":58,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"dda569d3-7088-4ac1-aead-f415d6973468"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        v1                                                 v2\n","0      ham  Go until jurong point, crazy.. Available only ...\n","1      ham                      Ok lar... Joking wif u oni...\n","2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3      ham  U dun say so early hor... U c already then say...\n","4      ham  Nah I don't think he goes to usf, he lives aro...\n","...    ...                                                ...\n","5567  spam  This is the 2nd time we have tried 2 contact u...\n","5568   ham              Will Ì_ b going to esplanade fr home?\n","5569   ham  Pity, * was in mood for that. So...any other s...\n","5570   ham  The guy did some bitching but I acted like i'd...\n","5571   ham                         Rofl. Its true to its name\n","\n","[5572 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-2d03099e-ae39-4662-b41e-15bd67969abb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5567</th>\n","      <td>spam</td>\n","      <td>This is the 2nd time we have tried 2 contact u...</td>\n","    </tr>\n","    <tr>\n","      <th>5568</th>\n","      <td>ham</td>\n","      <td>Will Ì_ b going to esplanade fr home?</td>\n","    </tr>\n","    <tr>\n","      <th>5569</th>\n","      <td>ham</td>\n","      <td>Pity, * was in mood for that. So...any other s...</td>\n","    </tr>\n","    <tr>\n","      <th>5570</th>\n","      <td>ham</td>\n","      <td>The guy did some bitching but I acted like i'd...</td>\n","    </tr>\n","    <tr>\n","      <th>5571</th>\n","      <td>ham</td>\n","      <td>Rofl. Its true to its name</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5572 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d03099e-ae39-4662-b41e-15bd67969abb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2d03099e-ae39-4662-b41e-15bd67969abb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2d03099e-ae39-4662-b41e-15bd67969abb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["data['gt'] = data['v1'].map({'ham':0,'spam':1})\n","data['text'] = data.v2.copy()\n","data['text'] = data.text.apply(lambda x: x.lower())\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"gHnhvtdO41w6","executionInfo":{"status":"ok","timestamp":1669560975570,"user_tz":-420,"elapsed":23,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"72a15601-ab18-4f60-f559-9c80d9e83f28"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     v1                                                 v2  gt  \\\n","0   ham  Go until jurong point, crazy.. Available only ...   0   \n","1   ham                      Ok lar... Joking wif u oni...   0   \n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   1   \n","3   ham  U dun say so early hor... U c already then say...   0   \n","4   ham  Nah I don't think he goes to usf, he lives aro...   0   \n","\n","                                                text  \n","0  go until jurong point, crazy.. available only ...  \n","1                      ok lar... joking wif u oni...  \n","2  free entry in 2 a wkly comp to win fa cup fina...  \n","3  u dun say so early hor... u c already then say...  \n","4  nah i don't think he goes to usf, he lives aro...  "],"text/html":["\n","  <div id=\"df-8199d36d-36a2-440b-a242-65afd0e2ab34\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","      <th>gt</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>0</td>\n","      <td>go until jurong point, crazy.. available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","      <td>0</td>\n","      <td>ok lar... joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>1</td>\n","      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","      <td>0</td>\n","      <td>u dun say so early hor... u c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>0</td>\n","      <td>nah i don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8199d36d-36a2-440b-a242-65afd0e2ab34')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8199d36d-36a2-440b-a242-65afd0e2ab34 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8199d36d-36a2-440b-a242-65afd0e2ab34');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(data['text'], data[\"gt\"], test_size=0.2, random_state=0)\n","X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"],"metadata":{"id":"y57qWstc4-8J","executionInfo":{"status":"ok","timestamp":1669560979246,"user_tz":-420,"elapsed":6,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["sentences = data['text']\n","labels = data['gt']\n","len(sentences), len(labels)"],"metadata":{"id":"e_NnXhqD5Exq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669560981148,"user_tz":-420,"elapsed":14,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"1b1e4d95-2262-499d-a294-f3db56568668"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5572, 5572)"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["# 1. Chạy mô hình bert-base-cased để xem kết quả thế nào"],"metadata":{"id":"838brCiji2E7"}},{"cell_type":"code","source":["MAX_LENGTH = 128\n","NUM_CLASSES = len(data[\"gt\"].unique())\n","MODEL_NAME = 'bert-base-cased'\n","MODEL_CONFIG = AutoConfig.from_pretrained(MODEL_NAME)"],"metadata":{"id":"PtnDOVzw5IYm","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["590b7cb4af7948c3bf83ab1d0c8b5ce5","58e0a3a96fe64e4989574b8d4caebdb0","6542f690b413430781b99c8904495627","77bf77c07b604e9883d9184a74b57d7c","df09e6a2f0954b5cbbaeff5bd60b9cea","8aa6950f822f4de2a7ff11da4c6394b3","726e80489ab24721b1d91a14d03f04d5","808b6d5918a4402699f7bb6d42de1c68","cfa2dfb3303a45edaaf02397ab34643a","0171eb5afe554e5e8d06476ea51f59d2","5cba0ae4958b446d83960eebdb05655c"]},"executionInfo":{"status":"ok","timestamp":1669560988330,"user_tz":-420,"elapsed":2344,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"938121e0-fd6c-47f0-8ba9-d77f4dec99d7"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"590b7cb4af7948c3bf83ab1d0c8b5ce5"}},"metadata":{}}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False, add_special_tokens=True,\n","                                                max_length=MAX_LENGTH, pad_to_max_length=True, use_fast=True)"],"metadata":{"id":"DLtDDsYP5NAi","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["64d1caa771fa4ece9549e7caf6aef187","e478c42263a0408983f6800f850bfd6f","588110a441c3431d98fb6e19603eeab0","df7b72d1dc94489ba61d3da216b6860e","bf75a3fa0fc84820b8eb17ab1117585f","50f6a197a97c42c799aea0fc9657548d","6ebcbda7061041a58e126e16d24f9136","249580aeee4e43459479d2689fdbb1cf","0756b7ff41f34519af74c209645f123f","550c0389df224a4982d6e463d22f9f7c","81507a37d46445b6a681149840277d24","10f6f8c27f7c4d9e8491b9c1ebcf43a2","0cfc0f602dd3467c81eb9b0f51c99375","3cc555752cab4521b440b865b60f4f5b","f6b3554691cc4e37b3e33ec3fad79f16","72ead08ca2434939a055e64a3164f9e0","c11992812a564c8ca5d9bc4127ce9b01","83e1d238e31a4e89801ee3e32c4e5e6e","38c2fe6a799d493297f29be3f13300fc","247b2ed178734636bf01e1aba2f8ea5c","9327fe76247d4f35872df5464371b790","0ad9d7cf4b134310830ea36f4e17f656","30d98744e09b4359bf768a393b3d07cd","05956bd6fada437ab6cb4fb34775e089","b3ed5f1078874830b9c027ed71d0596b","43d1d397539a4b22a0986541858a235c","118e7e26831e4ab3bbf56304e0741cd6","13dbe7abe6624ce2b47e5010c73c700b","6a8d8d1f279646babdba177c0fbcf753","d3d55ce66e5b465e8c2a5d434f07cd88","d799c5aeaca6462e8c95eb68d707d417","2e1d9e7371934ecb96a93842ccec49bd","45725aa555524a7fa185c335ad3f0c24"]},"executionInfo":{"status":"ok","timestamp":1669561000651,"user_tz":-420,"elapsed":9373,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"55c3df7f-ac3a-430c-f329-1fde84535ad9"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64d1caa771fa4ece9549e7caf6aef187"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10f6f8c27f7c4d9e8491b9c1ebcf43a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30d98744e09b4359bf768a393b3d07cd"}},"metadata":{}}]},{"cell_type":"code","source":["def Tokenizer(sentences):\n","    input_ids=[]\n","    attention_masks=[]\n","\n","    for sent in tqdm(sentences):\n","        bert_inp=tokenizer.encode_plus(sent, add_special_tokens = True ,max_length=MAX_LENGTH, pad_to_max_length = True, return_attention_mask = True)\n","        input_ids.append(bert_inp['input_ids'])\n","        attention_masks.append(bert_inp['attention_mask'])\n","\n","    input_ids=np.asarray(input_ids)\n","    attention_masks=np.array(attention_masks)\n","    return input_ids, attention_masks"],"metadata":{"id":"Olo4tOgM5W3L","executionInfo":{"status":"ok","timestamp":1669561003326,"user_tz":-420,"elapsed":6,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["input_ids_train, attention_masks_train = Tokenizer(X_train)\n","input_ids_test, attention_masks_test = Tokenizer(X_test)\n","input_ids_valid, attention_masks_vaild = Tokenizer(X_valid)"],"metadata":{"id":"c0sZ6VUw5ZIK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669561007947,"user_tz":-420,"elapsed":1604,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"47302d7b-66cd-4588-f6b8-8b5b0b7d08aa"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/3342 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100%|██████████| 3342/3342 [00:00<00:00, 8410.28it/s]\n","100%|██████████| 1115/1115 [00:00<00:00, 8482.95it/s]\n","100%|██████████| 1115/1115 [00:00<00:00, 8320.48it/s]\n"]}]},{"cell_type":"code","source":["def create_model(config=MODEL_CONFIG):\n","    config.output_hidden_states = False\n","    transformer_model = TFAutoModel.from_pretrained(MODEL_NAME, config=config)\n","\n","    input_ids_in = tf.keras.layers.Input(shape=(MAX_LENGTH,), name='input_token', dtype='int32')\n","    input_masks_in = tf.keras.layers.Input(shape=(MAX_LENGTH,), name='masked_token', dtype='int32') \n","    embedding_layer = transformer_model(input_ids_in, input_masks_in)[0][:, 0, :]\n","\n","    X = tf.keras.layers.Dense(20, activation='relu')(embedding_layer)\n","    X = tf.keras.layers.Dropout(0.2)(X)\n","\n","    X = tf.keras.layers.Dense(10, activation='relu')(X)\n","    X = tf.keras.layers.Dropout(0.2)(X)\n","\n","    X = tf.keras.layers.Dense(1, activation='sigmoid')(X)\n","    model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)\n","    return model"],"metadata":{"id":"HDpXDdzy5clB","executionInfo":{"status":"ok","timestamp":1669561019272,"user_tz":-420,"elapsed":599,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["model = create_model()\n","model.summary()"],"metadata":{"id":"0sFmw5A05ijn","colab":{"base_uri":"https://localhost:8080/","height":850,"referenced_widgets":["3df7d791e7f34e9dae933f943f32b61c","5de1b326da56446e8787dafb936497fb","055d3495fd6440818450070b527b3737","13c9fa899bbe4604aa242687526147c0","00ef9de6759a4552888f87a25d17ac90","637d247cef9146c98ac697ee135485ae","b6cc55713a674a338ecd1af8cd22ae59","11caa175a7724b6d89776e0c87f968c2","30395471d98440cba38591d457976592","0d0d3c46847b4cf3b03de365ba03a583","77541e5cd09d4ad9935dd7b6f726ce75"]},"executionInfo":{"status":"ok","timestamp":1669561047288,"user_tz":-420,"elapsed":24952,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"94e2560b-e2ac-4a2c-83bb-d23aea01e6ce"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/527M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3df7d791e7f34e9dae933f943f32b61c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_token (InputLayer)       [(None, 128)]        0           []                               \n","                                                                                                  \n"," masked_token (InputLayer)      [(None, 128)]        0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_token[0][0]',            \n","                                thPoolingAndCrossAt               'masked_token[0][0]']           \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 128,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n"," ingOpLambda)                                                                                     \n","                                                                                                  \n"," dense (Dense)                  (None, 20)           15380       ['tf.__operators__.getitem[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dropout_37 (Dropout)           (None, 20)           0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 10)           210         ['dropout_37[0][0]']             \n","                                                                                                  \n"," dropout_38 (Dropout)           (None, 10)           0           ['dense_1[0][0]']                \n","                                                                                                  \n"," dense_2 (Dense)                (None, 1)            11          ['dropout_38[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 108,325,873\n","Trainable params: 108,325,873\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(loss=\"binary_crossentropy\", \n","              optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"OSi5n6Vk5618","executionInfo":{"status":"ok","timestamp":1669561055236,"user_tz":-420,"elapsed":14,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# mc = tf.keras.callbacks.ModelCheckpoint(filepath=\"./best_model.hdf5\",\n","#                                         monitor=\"val_accuracy\",\n","#                                         verbos=1,\n","#                                         save_best_only=True,\n","#                                         mode=\"max\")\n","\n","history = model.fit([input_ids_train, attention_masks_train], \n","                    y_train,\n","                    batch_size=32, \n","                    epochs=5,\n","                    callbacks=None,\n","                    validation_data=([input_ids_valid, attention_masks_vaild], y_valid)\n","                    )"],"metadata":{"id":"V1fO__WO58AP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669561576983,"user_tz":-420,"elapsed":517062,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"59762867-51d2-4ad0-ea6c-eac24d017633"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stdout","text":["105/105 [==============================] - 108s 883ms/step - loss: 0.2159 - accuracy: 0.9180 - val_loss: 0.0536 - val_accuracy: 0.9848\n","Epoch 2/5\n","105/105 [==============================] - 92s 874ms/step - loss: 0.0777 - accuracy: 0.9820 - val_loss: 0.0466 - val_accuracy: 0.9874\n","Epoch 3/5\n","105/105 [==============================] - 92s 873ms/step - loss: 0.0509 - accuracy: 0.9874 - val_loss: 0.0581 - val_accuracy: 0.9865\n","Epoch 4/5\n","105/105 [==============================] - 92s 876ms/step - loss: 0.0318 - accuracy: 0.9922 - val_loss: 0.0599 - val_accuracy: 0.9857\n","Epoch 5/5\n","105/105 [==============================] - 92s 874ms/step - loss: 0.0309 - accuracy: 0.9931 - val_loss: 0.0633 - val_accuracy: 0.9874\n"]}]},{"cell_type":"code","source":["model.evaluate([input_ids_test, attention_masks_test], y_test)"],"metadata":{"id":"dUbViKMy6Dca","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669561594028,"user_tz":-420,"elapsed":10528,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"71a8a1cf-2ec9-48a9-def8-05d38c0cce96"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["35/35 [==============================] - 10s 276ms/step - loss: 0.0335 - accuracy: 0.9955\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.033514901995658875, 0.9955157041549683]"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["# 2. Thay Bert bằng xlnet-base-cased để chạy thử xem kết quả thế nào"],"metadata":{"id":"vprrBgqYij-s"}},{"cell_type":"code","source":["MODEL_NAME = 'xlnet-base-cased'\n","MODEL_CONFIG = AutoConfig.from_pretrained(MODEL_NAME)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["18c6a42936a04d6ab9576ad705087d4f","bd06d76784a343f898cdf1c2ebea535f","d6093060b7dc4a088830994d0286c56a","096ef0abbfe44b6cb5a6c15e46c002a2","6da6ee62628940c19facdb908045fbc2","60f0242ed2ca4a308e6c888fa88364e3","29fc053994374b11a9977821b15e13d5","088ae864ae9b4a6d820c48a1ae020ac6","f135580612f140feb1b765bafbd3916a","a7cf75f356ca4c4daf98f5a7a9bea485","65f3910be1be49ef8f8276525dd3ed5c"]},"id":"OCK2Dny5gBk-","executionInfo":{"status":"ok","timestamp":1669561693775,"user_tz":-420,"elapsed":1947,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"2d0c7668-4b1d-40a6-98f7-2ae23ba3f51b"},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18c6a42936a04d6ab9576ad705087d4f"}},"metadata":{}}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False, add_special_tokens=True,\n","                                                max_length=MAX_LENGTH, pad_to_max_length=True, use_fast=True)"],"metadata":{"id":"yl6vVaVcgcQZ","executionInfo":{"status":"ok","timestamp":1669564867176,"user_tz":-420,"elapsed":4321,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["input_ids_train, attention_masks_train = Tokenizer(X_train)\n","input_ids_test, attention_masks_test = Tokenizer(X_test)\n","input_ids_valid, attention_masks_vaild = Tokenizer(X_valid)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"54r9iKseiHk0","executionInfo":{"status":"ok","timestamp":1669561722455,"user_tz":-420,"elapsed":1442,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"68c43e25-2a9f-4bd5-e007-47d18aff2383"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/3342 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2310: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100%|██████████| 3342/3342 [00:00<00:00, 6849.60it/s]\n","100%|██████████| 1115/1115 [00:00<00:00, 7708.80it/s]\n","100%|██████████| 1115/1115 [00:00<00:00, 6966.40it/s]\n"]}]},{"cell_type":"code","source":["model_2 = create_model(MODEL_CONFIG)\n","model_2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LCOyxqVGgwXp","executionInfo":{"status":"ok","timestamp":1669565576683,"user_tz":-420,"elapsed":4582,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"1a0c1b21-19b0-4c7b-9952-c0a324f81c7d"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n","- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_token (InputLayer)       [(None, 128)]        0           []                               \n","                                                                                                  \n"," masked_token (InputLayer)      [(None, 128)]        0           []                               \n","                                                                                                  \n"," tfxl_net_model_2 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_token[0][0]',            \n"," )                              last_hidden_state=(               'masked_token[0][0]']           \n","                                None, 128, 768),                                                  \n","                                 mems=((128, None,                                                \n","                                768),                                                             \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768)),                                               \n","                                 hidden_states=None                                               \n","                                , attentions=None)                                                \n","                                                                                                  \n"," tf.__operators__.getitem_5 (Sl  (None, 768)         0           ['tfxl_net_model_2[0][0]']       \n"," icingOpLambda)                                                                                   \n","                                                                                                  \n"," dense_15 (Dense)               (None, 20)           15380       ['tf.__operators__.getitem_5[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dropout_269 (Dropout)          (None, 20)           0           ['dense_15[0][0]']               \n","                                                                                                  \n"," dense_16 (Dense)               (None, 10)           210         ['dropout_269[0][0]']            \n","                                                                                                  \n"," dropout_270 (Dropout)          (None, 10)           0           ['dense_16[0][0]']               \n","                                                                                                  \n"," dense_17 (Dense)               (None, 1)            11          ['dropout_270[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 116,733,937\n","Trainable params: 116,733,937\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_2.compile(loss=\"binary_crossentropy\", \n","              optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"yYbW6GCbgz0i","executionInfo":{"status":"ok","timestamp":1669565583363,"user_tz":-420,"elapsed":518,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# mc = tf.keras.callbacks.ModelCheckpoint(filepath=\"./best_model_2.hdf5\",\n","#                                         monitor=\"val_accuracy\",\n","#                                         verbos=1,\n","#                                         save_best_only=True,\n","#                                         mode=\"max\")\n","\n","history = model_2.fit([input_ids_train, attention_masks_train], \n","                    y_train,\n","                    batch_size=32, \n","                    epochs=5,\n","                    callbacks=None,\n","                    validation_data=([input_ids_valid, attention_masks_vaild], y_valid)\n","                    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i5XGakKtg44J","executionInfo":{"status":"ok","timestamp":1669566227917,"user_tz":-420,"elapsed":247213,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"cdf0322e-8391-42c5-bfe0-5144b0db82a3"},"execution_count":41,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/5\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stdout","text":["105/105 [==============================] - 135s 1s/step - loss: 0.3673 - accuracy: 0.8181 - val_loss: 0.1394 - val_accuracy: 0.9695\n","Epoch 2/5\n","105/105 [==============================] - 118s 1s/step - loss: 0.1623 - accuracy: 0.9333 - val_loss: 0.0617 - val_accuracy: 0.9821\n","Epoch 3/5\n","105/105 [==============================] - 118s 1s/step - loss: 0.1211 - accuracy: 0.9581 - val_loss: 0.0486 - val_accuracy: 0.9839\n","Epoch 4/5\n","105/105 [==============================] - 118s 1s/step - loss: 0.0937 - accuracy: 0.9692 - val_loss: 0.0573 - val_accuracy: 0.9857\n","Epoch 5/5\n","105/105 [==============================] - 118s 1s/step - loss: 0.0825 - accuracy: 0.9728 - val_loss: 0.0586 - val_accuracy: 0.9857\n"]}]},{"cell_type":"code","source":["model_2.evaluate([input_ids_test, attention_masks_test], y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkO7er8ihuJ5","executionInfo":{"status":"ok","timestamp":1669566246327,"user_tz":-420,"elapsed":12435,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"96fcab07-11b4-428a-a03d-55bf52eefec1"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["35/35 [==============================] - 12s 344ms/step - loss: 0.0294 - accuracy: 0.9919\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.02939586527645588, 0.9919282793998718]"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["# 3. Theo như bài tập số 2 ở những layers cuối hãy thay thành các FC layers có số units lần lượt là 50, 30, 10"],"metadata":{"id":"-g6TTYeQiWlo"}},{"cell_type":"code","source":["def create_model_3(config=MODEL_CONFIG):\n","    config.output_hidden_states = False\n","    transformer_model = TFAutoModel.from_pretrained(MODEL_NAME, config=config)\n","\n","    input_ids_in = tf.keras.layers.Input(shape=(MAX_LENGTH,), name='input_token', dtype='int32')\n","    input_masks_in = tf.keras.layers.Input(shape=(MAX_LENGTH,), name='masked_token', dtype='int32') \n","    embedding_layer = transformer_model(input_ids_in, input_masks_in)[0][:, 0, :]\n","\n","    X = tf.keras.layers.Dense(50, activation='relu')(embedding_layer)\n","    X = tf.keras.layers.Dropout(0.2)(X)\n","\n","    X = tf.keras.layers.Dense(30, activation='relu')(X)\n","    X = tf.keras.layers.Dropout(0.2)(X)\n","\n","    X = tf.keras.layers.Dense(10, activation='relu')(X)\n","    X = tf.keras.layers.Dropout(0.2)(X)\n","\n","    X = tf.keras.layers.Dense(1, activation='sigmoid')(X)\n","    model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = X)\n","    return model"],"metadata":{"id":"m5bsrVynh3y_","executionInfo":{"status":"ok","timestamp":1669566666749,"user_tz":-420,"elapsed":537,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["model_3 = create_model_3()\n","model_3.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vg9xQCsFh99O","executionInfo":{"status":"ok","timestamp":1669566672912,"user_tz":-420,"elapsed":3908,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"a840b96a-35d5-431f-ed76-93ef221ddab7"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n","- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_7\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_token (InputLayer)       [(None, 128)]        0           []                               \n","                                                                                                  \n"," masked_token (InputLayer)      [(None, 128)]        0           []                               \n","                                                                                                  \n"," tfxl_net_model_4 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_token[0][0]',            \n"," )                              last_hidden_state=(               'masked_token[0][0]']           \n","                                None, 128, 768),                                                  \n","                                 mems=((128, None,                                                \n","                                768),                                                             \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768),                                                \n","                                 (128, None, 768)),                                               \n","                                 hidden_states=None                                               \n","                                , attentions=None)                                                \n","                                                                                                  \n"," tf.__operators__.getitem_7 (Sl  (None, 768)         0           ['tfxl_net_model_4[0][0]']       \n"," icingOpLambda)                                                                                   \n","                                                                                                  \n"," dense_21 (Dense)               (None, 50)           38450       ['tf.__operators__.getitem_7[0][0\n","                                                                 ]']                              \n","                                                                                                  \n"," dropout_347 (Dropout)          (None, 50)           0           ['dense_21[0][0]']               \n","                                                                                                  \n"," dense_22 (Dense)               (None, 30)           1530        ['dropout_347[0][0]']            \n","                                                                                                  \n"," dropout_348 (Dropout)          (None, 30)           0           ['dense_22[0][0]']               \n","                                                                                                  \n"," dense_23 (Dense)               (None, 10)           310         ['dropout_348[0][0]']            \n","                                                                                                  \n"," dropout_349 (Dropout)          (None, 10)           0           ['dense_23[0][0]']               \n","                                                                                                  \n"," dense_24 (Dense)               (None, 1)            11          ['dropout_349[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 116,758,637\n","Trainable params: 116,758,637\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_3.compile(loss=\"binary_crossentropy\", \n","              optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"4MQvTQfziMcj","executionInfo":{"status":"ok","timestamp":1669566675803,"user_tz":-420,"elapsed":685,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["# mc = tf.keras.callbacks.ModelCheckpoint(filepath=\"./best_model_3.hdf5\",\n","#                                         monitor=\"val_accuracy\",\n","#                                         verbos=1,\n","#                                         save_best_only=True,\n","#                                         mode=\"max\")\n","\n","history = model_3.fit([input_ids_train, attention_masks_train], \n","                    y_train,\n","                    batch_size=32, \n","                    epochs=5,\n","                    callbacks=None,\n","                    validation_data=([input_ids_valid, attention_masks_vaild], y_valid)\n","                    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5B7zs2ZXiOeg","executionInfo":{"status":"ok","timestamp":1669567284673,"user_tz":-420,"elapsed":605939,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"69e53ca8-6b61-410b-c18a-f85b005917d9"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_4/transformer/mask_emb:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_4/transformer/mask_emb:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stdout","text":["105/105 [==============================] - 135s 1s/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.2975 - val_accuracy: 0.8735\n","Epoch 2/5\n","105/105 [==============================] - 118s 1s/step - loss: 0.2883 - accuracy: 0.8767 - val_loss: 0.1018 - val_accuracy: 0.9776\n","Epoch 3/5\n","105/105 [==============================] - 118s 1s/step - loss: 0.1675 - accuracy: 0.9402 - val_loss: 0.0587 - val_accuracy: 0.9848\n","Epoch 4/5\n","105/105 [==============================] - 118s 1s/step - loss: 0.1257 - accuracy: 0.9575 - val_loss: 0.0533 - val_accuracy: 0.9839\n","Epoch 5/5\n","105/105 [==============================] - 118s 1s/step - loss: 0.1213 - accuracy: 0.9608 - val_loss: 0.0442 - val_accuracy: 0.9874\n"]}]},{"cell_type":"code","source":["model_3.evaluate([input_ids_test, attention_masks_test], y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y436CPlTiRhb","executionInfo":{"status":"ok","timestamp":1669567496616,"user_tz":-420,"elapsed":21242,"user":{"displayName":"Trí Huỳnh Khoang","userId":"03707979523422614967"}},"outputId":"a23d323a-cd25-457d-f7cb-9513dcef83f3"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["35/35 [==============================] - 12s 344ms/step - loss: 0.0386 - accuracy: 0.9848\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.038551460951566696, 0.9847533702850342]"]},"metadata":{},"execution_count":52}]}]}